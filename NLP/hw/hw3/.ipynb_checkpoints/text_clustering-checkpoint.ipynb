{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 问题引入"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "聚类分析(cluster analysis)，也被称为数据分割(data segmentation)。是指将一组对象的集合分组或分割为几个子集或类(cluster)，每个类别中的对象之间的相似度要高于与其他类别中对象的相似度，可以用不同的量度来描述相似度。有时候，类别之间也具有层级关系(hierarchy)。聚类分析的核心在于如何度量对象之间的相似度或非相似度(dissimilarity)，度量的方式类似于监督学习中的损失函数。下面将先讨论一般性的聚类问题，然后针对文本聚类，实现两种常用的聚类方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 计算模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 相似度矩阵(proximity matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "相似度是指两个对象之间的相似程度，可以用一个$N\\times N$的矩阵$\\mathbf{D}$来表示，其中$N$代表对象的个数，$d_{ii'}$记录了第$i$个对象和第$i'$个对象的相似度。相似度矩阵一般作为聚类算法的输入。\n",
    "\n",
    "大多数聚类算法都假定相似度矩阵的所有元素都是非负的，对角线元素均为0。大多数算法也假定相似度矩阵是对称的，如果不对称，则用$(\\mathbf{D}+\\mathbf{D^T})/2$来代替$D$。在严格意义上，大多数情况下的相似度并不具有距离(distance)的含义，因为三角不等式在这种情况下不会成立($d_{ii'}\\leq d_{ik}+d_{i'k}$)。\n",
    "\n",
    "我们用$x_{ij}$来表示对象的属性(attribute)，$i=1,2,\\cdots,N$，$j=1,2,\\cdots,p$。定义非相似度$d_j(x_{ij},x_{i'j})$，表示第$j$组属性的非相似度，则：\n",
    "$$\n",
    "D(x_i,x_{i'})=\\sum_{j=1}^p d_j(x_{ij},x_{i'j})\n",
    "$$\n",
    "就是对象$i$和$i'$之间的非相似度。最常用的就是对象之间的平方距离：\n",
    "$$\n",
    "d_j(x_{ij},x_{i'j})=(x_{ij}-x_{i'j})^2\n",
    "$$\n",
    "对于一些不能量化的属性，平方距离将不再适用，可以用一些其他的方法表示两个对象之间的非相似度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 聚类算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "目前主要有以下几种分类算法：组合算法，混合模型和模式匹配。\n",
    "\n",
    "组合算法直接观察数据，不考虑数据内部服从的概率模型。混合模型假设数据都服从某个独立同分布，整体数据的分布是某几个不同参数分布的叠加，每个分布就是一个类别，通常通过最大似然估计来确定各个模型的参数。模式匹配就是直接估计出概率分布函数的模式，最符合某个独立模式的一批样本属于同一个分类。\n",
    "\n",
    "下面主要讨论组合算法中的K-means方法和混合模型中的高斯混合模型方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 K-means聚类算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最受欢迎的聚类算法就是直接学习出每个样本所属的分类而不去考虑数据的概率模型。每个样本都用一个整数$i\\in\\{1,\\cdots,N\\}$来标记，人为的确定某个整数$K<N$，每个样本所属的类别为$k\\in\\{1,\\cdots,K\\}$。每个样本将被分为某个唯一的类别。这些从样本编号到类别编号的映射关系就是分类器$k=C(i)$。我们需要基于每对样本值的非相似度，找到某个最优的分类器$k=C^*(i)$。最优的目标就是调整映射关系，最小化损失函数(表征距实现聚类目标远近的程度)。为了将相似的样本都划分到同一类别，定义如下损失函数：\n",
    "$$\n",
    "W(C)=\\frac{1}{2}\\sum_{k=1}^K\\sum_{C(i)=k}\\sum_{C(i')=k}d(x_i,x_{i'})\n",
    "$$\n",
    "即相同类别的样本之间的相似度往往很高。\n",
    "\n",
    "K-means算法是比较常用的迭代聚类方法，它适用于样本属性均为可量化类型的情况。K-means选择平方欧氏距离来衡量样本间的非相似度：\n",
    "$$\n",
    "d(x_i,x_{i'})=\\sum_{j=1}^p(x_{ij}-x_{i'j})=||x_i-x_{i'}||^2\n",
    "$$\n",
    "则上述损失函数就可以简化为：\n",
    "\n",
    "\\begin{align*}\n",
    " W(C)&= \\frac{1}{2}\\sum_{k=1}^K\\sum_{C(i)=k}\\sum_{C(i')=k}d(x_i,x_{i'}) \\\\\n",
    "     &= \\sum_{k=1}^K N_k\\sum_{C(i)=k} ||x_i-\\overline{x}_k|| ^2\n",
    "\\end{align*} \n",
    "\n",
    "其中，$\\overline{x}_k=(\\overline{x}_{1k},\\cdots,\\overline{x}_{pk},)$表示第$k$类样本向量的均值，$N_k=\\sum_{i=1}^N I(C(i)=k)$。因此，我们优化的目标就是找到某个最优的分类器：\n",
    "$$\n",
    "C^*=\\min_C \\sum_{k=1}^K N_k\\sum_{C(i)=k}||x_i-\\overline{x}_k||^2\n",
    "$$\n",
    "注意到，对于任意样本集合都有：\n",
    "$$\n",
    "\\overline{x}_S=argmin_m\\sum_{i\\in S}||x_i-m||^2\n",
    "$$\n",
    "即求解如下的优化问题：\n",
    "$$\n",
    "\\min_{C,\\{m_k\\}_1^K} \\sum_{k=1}^K N_k\\sum_{C(i)=k}||x_i-m_k||^2\n",
    "$$\n",
    "\n",
    "下面是K-means聚类的算法流程：\n",
    "1. 生成初始值$m_k$\n",
    "2. 对于每个$i$，更新分类器的值：$C(i)=argmax_{1\\leq k\\leq K}||x_i-m_k||^2$\n",
    "3. 更新均值向量的值：$m_k=\\frac{1}{N_k}\\sum_{C(i)=k}x_i$\n",
    "4. 如果未收敛，则回到步骤2，直至收敛。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 高斯混合模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "高斯混合模型假设每个类别的数据都服从相互独立的高斯分布，通过极大似然估计和EM算法确定每个高斯分布的参数值，最后根据确定的高斯分布求出样本属于某高斯模型的概率，取得最大概率的高斯分布所属的类别就是样本的类别。\n",
    "\n",
    "高斯模型的线性混合：\n",
    "$$\n",
    "p(x)=\\sum_{k=1}^K \\pi_k \\mathcal{N}(\\mathbf{x}|\\mathbf{\\mu}_k, \\mathbf{\\Sigma}_k)\n",
    "$$\n",
    "混合系数为：\n",
    "$$\n",
    "\\sum_{k=1}^K \\pi_k=1,0\\leq\\pi_k\\leq 1\n",
    "$$\n",
    "上述公式其实可以看做一种先验概率：\n",
    "$$\n",
    "p(x)=\\sum_{k=1}^K p(k)p(\\mathbf{x}|k)\n",
    "$$\n",
    "下面估计相应类别标签$k$的后验概率(responsibilities)：\n",
    "\\begin{align*}\n",
    "\\gamma_k=p(k|\\mathbf{x})=& \\frac{p(k)p(\\mathbf{x}|k)}{p(\\mathbf{x})} \\\\\n",
    "                        =& \\frac{\\pi_k\\mathcal{N}(\\mathbf{x}|\\mathbf{\\mu}_k, \\mathbf{\\Sigma}_k)}{\\sum_{j=1}^K\\pi_j\\mathcal{N}(\\mathbf{x}|\\mathbf{\\mu}_j, \\mathbf{\\Sigma}_j)}\n",
    "\\end{align*}\n",
    "\n",
    "使用极大似然估计：\n",
    "$$\n",
    "\\ln p(D|\\mathbf{\\pi},\\mathbf{\\mu}, \\mathbf{\\Sigma})=\\sum_{n=1}^N \\ln\\{\\sum_{k=1}^K \\pi_k\\mathcal{N}(\\mathbf{x}_n|\\mathbf{\\mu}_k, \\mathbf{\\Sigma}_k)\\}\n",
    "$$\n",
    "\n",
    "由于极大似然估计的解不是封闭形式(变量之间互为耦合)，故采用EM算法进行迭代求解。\n",
    "\n",
    "首先给参数设定一个初始值，通过以下两个步骤更新参数直至收敛：\n",
    "\n",
    "E-step: 估计后验概率\n",
    "$$\n",
    "\\gamma_k(x_i)= \\frac{\\pi_k\\mathcal{N}(\\mathbf{x}_i|\\mathbf{\\mu}_k, \\mathbf{\\Sigma}_k)}{\\sum_{j=1}^K\\pi_j\\mathcal{N}(\\mathbf{x_i}|\\mathbf{\\mu}_j, \\mathbf{\\Sigma}_j)}\n",
    "$$\n",
    "M-step：采用MLE更新参数\n",
    "$$\n",
    "\\mu_k=\\frac{1}{N_k}\\sum_{i=1}^N \\gamma_k(x_i)\n",
    "$$\n",
    "$$\n",
    "\\Sigma_k=\\frac{1}{N_k}\\sum_{i=1}^N \\gamma_k(x_i)(x_i-\\mu_k)(x_i-\\mu_k)^T\n",
    "$$\n",
    "$$\n",
    "\\pi_k=\\frac{1}{N}\\sum_{i=1}^N \\gamma_k(x_i)\n",
    "$$\n",
    "\n",
    "分类时，只要把每个数据点带入到每个混合成分$C_k$中，当概率大于一定阈值时便认为其属于$C_k$类。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 编程实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import scipy\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import importlib\n",
    "import sys \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "load_data = scipy.io.loadmat('data/news_data.mat')\n",
    "news_data = load_data['data']\n",
    "news_labels = load_data['labels']\n",
    "\n",
    "# shuffle\n",
    "zipped_data = list(zip(news_data, news_labels))  \n",
    "random.seed(0)\n",
    "random.shuffle(zipped_data)\n",
    "new_zipped_data = list(map(list, zip(*zipped_data)))  \n",
    "news_data, news_labels = np.array(new_zipped_data[0]), np.array(new_zipped_data[1])  \n",
    "\n",
    "# split data into training and test sets\n",
    "training_data = news_data[:1000, 4900:]\n",
    "training_labels = news_labels[:1000]\n",
    "test_data = news_data[15000:, :]\n",
    "test_labels = news_labels[15000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means\n",
    "class KMeans:\n",
    "    def __init__(self):\n",
    "        # K\n",
    "        self.K = 0\n",
    "        # assignments\n",
    "        self.C = 0\n",
    "        # mean vectors\n",
    "        self.m = 0\n",
    "        # loss function\n",
    "        self.loss_fn = 0\n",
    "        # N data points\n",
    "        self.N = 0\n",
    "        # dimension\n",
    "        self.d = 0\n",
    "        \n",
    "    def generate_random_means(self, data):\n",
    "        m = np.zeros((self.K, self.d))\n",
    "        for k in range(self.K):\n",
    "            m[k] = data[int(random.random()*self.N)]\n",
    "        return m\n",
    "    \n",
    "    def squared_euclidean_dist(self, u, v):\n",
    "        diff = u - v\n",
    "        return sum(diff*diff)\n",
    "    \n",
    "    def fit(self, data, K, max_iter):\n",
    "        print(\"Start fitting...\")\n",
    "        self.K = K\n",
    "        self.N = data.shape[0]\n",
    "        self.d = data.shape[1]\n",
    "        self.C = np.zeros((self.N, 1))\n",
    "        self.loss_fn = np.zeros((self.N, 1))\n",
    "        \n",
    "        cnt = 0\n",
    "        self.m = self.generate_random_means(data)\n",
    "        \n",
    "        while cnt < max_iter:\n",
    "            changed = False\n",
    "            \n",
    "            for i in range(self.N):\n",
    "                min_dissimilarity = float('inf')\n",
    "                min_k = 0\n",
    "                for k in range(self.m.shape[0]):\n",
    "                    dissimilarity = self.squared_euclidean_dist(data[i], self.m[k])\n",
    "                    if dissimilarity < min_dissimilarity:\n",
    "                        min_dissimilarity = dissimilarity\n",
    "                        min_k = k\n",
    "                self.loss_fn[i] = min_dissimilarity\n",
    "                if self.C[i] != min_k:\n",
    "                    self.C[i] =min_k\n",
    "                    changed = True\n",
    "                    \n",
    "            for k in range(self.m.shape[0]):\n",
    "                data_k = data[self.C.ravel()==k]\n",
    "                if data_k.shape[0] != 0:\n",
    "                    self.m[k] = np.sum(data_k, axis=0) / data_k.shape[0]\n",
    "                \n",
    "            cnt += 1\n",
    "            if not changed:\n",
    "                print(\"converged!\")\n",
    "                break\n",
    "        \n",
    "        print(\"Finish fitting !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting...\n",
      "converged!\n",
      "Finish fitting !\n"
     ]
    }
   ],
   "source": [
    "km = KMeans()\n",
    "km.fit(training_data, 20, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.],\n",
       "       [15.],\n",
       "       [16.],\n",
       "       [10.],\n",
       "       [ 6.],\n",
       "       [ 3.],\n",
       "       [16.],\n",
       "       [ 7.],\n",
       "       [ 7.],\n",
       "       [16.],\n",
       "       [16.],\n",
       "       [19.],\n",
       "       [16.],\n",
       "       [16.],\n",
       "       [10.],\n",
       "       [ 7.],\n",
       "       [ 6.],\n",
       "       [ 7.],\n",
       "       [16.],\n",
       "       [ 3.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km.C[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Gaussian Mixture Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "load_data = scipy.io.loadmat('data/news_data.mat')\n",
    "news_data = load_data['data']\n",
    "news_labels = load_data['labels']\n",
    "\n",
    "# shuffle\n",
    "zipped_data = list(zip(news_data, news_labels))  \n",
    "random.seed(0)\n",
    "random.shuffle(zipped_data)\n",
    "new_zipped_data = list(map(list, zip(*zipped_data)))  \n",
    "news_data, news_labels = np.array(new_zipped_data[0]), np.array(new_zipped_data[1])  \n",
    "\n",
    "# split data into training and test sets\n",
    "training_data = news_data[:100, 4990:]\n",
    "training_labels = news_labels[:100]\n",
    "test_data = news_data[15000:, :]\n",
    "test_labels = news_labels[15000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means\n",
    "class GMM:\n",
    "    def __init__(self):\n",
    "        # K\n",
    "        self.K = 0\n",
    "        # N data points\n",
    "        self.N = 0\n",
    "        # dimension\n",
    "        self.d = 0\n",
    "        # prior\n",
    "        self.pi = 0\n",
    "        # means\n",
    "        self.u = 0\n",
    "        # covarience\n",
    "        self.sigma = 0\n",
    "        # responsibility\n",
    "        # self.r = 0\n",
    "        \n",
    "    def gaussian_pdf(self, x, u, sigma):\n",
    "        if np.linalg.det(sigma)==0:\n",
    "            return 0\n",
    "        if -(x-u).dot(scipy.linalg.pinv(sigma).dot(x.T-u.T))/2>100:\n",
    "            return 0\n",
    "        return 1/(np.sqrt(abs(np.linalg.det(sigma))))*np.exp(-(x-u).dot(scipy.linalg.pinv(sigma).dot(x.T-u.T))/2)\n",
    "        \n",
    "    # E step\n",
    "    def expectation_step(self, x, k):\n",
    "        numerator = self.pi[k]*self.gaussian_pdf(x, self.u[k], self.sigma[k])\n",
    "        denominator = sum([self.pi[j]*self.gaussian_pdf(x, self.u[j], self.sigma[j]) for j in range(self.K)])\n",
    "        if denominator==0:\n",
    "             return 0\n",
    "        return numerator/denominator\n",
    "        \n",
    "    # M step\n",
    "    def maximization_step(self, data, k):\n",
    "        N_k = self.r.sum()\n",
    "        pi_k = N_k/self.N\n",
    "        u_k = np.zeros(self.d)\n",
    "        for i in range(self.N):\n",
    "            u_k += self.r[k][i]*data[i]\n",
    "        sigma_k = np.zeros((self.d,self.d))\n",
    "        for i in range(self.N):\n",
    "            sigma_k += self.r[k][i]*(data[i].T-u_k.T).dot(data[i]-u_k)\n",
    "        sigma_k = sigma_k/N_k\n",
    "        return pi_k, u_k, sigma_k\n",
    "        \n",
    "    \n",
    "    def fit(self, data, K, max_iter):\n",
    "        print(\"Start fitting...\")\n",
    "        self.K = K\n",
    "        self.N = data.shape[0]\n",
    "        self.d = data.shape[1]\n",
    "        self.pi = np.ones((self.K, 1))/self.K\n",
    "        self.u = np.random.rand(self.K, self.d)\n",
    "        self.sigma = np.zeros((self.K, self.d, self.d))\n",
    "        for k in range(self.K):\n",
    "            self.sigma[k] = np.random.rand(self.d, self.d)\n",
    "        self.r = np.zeros((self.K, self.N))\n",
    "        \n",
    "        cnt = 0        \n",
    "        while cnt < max_iter:\n",
    "            changed = False\n",
    "            \n",
    "            # E step\n",
    "            for k in range(self.K):\n",
    "                for i in range(self.N):\n",
    "                    r_ki = self.expectation_step(data[i], k)\n",
    "                    if r_ki != self.r[k][i]:\n",
    "                        self.r[k][i] = r_ki\n",
    "                        changed = True\n",
    "            \n",
    "            # M step\n",
    "            for k in range(self.K):\n",
    "                pi_k, u_k, sigma_k = self.maximization_step(data, k)\n",
    "                if pi_k.all()!=self.pi[k].all() or u_k.all()!=self.u[k].all() or sigma_k.all()!=self.sigma[k].all():\n",
    "                    self.pi[k], self.u[k], self.sigma[k] = pi_k, u_k, sigma_k\n",
    "                    changed = True\n",
    "                \n",
    "            cnt += 1\n",
    "            if not changed:\n",
    "                print(\"converged!\")\n",
    "                break\n",
    "        print(\"Finish fitting !\")\n",
    "        \n",
    "    def predict(self, x):\n",
    "        k_pred = 0\n",
    "        max_prob = 0\n",
    "        for k in range(self.K):\n",
    "            prob = 1/(np.sqrt(abs(np.linalg.det(self.sigma[k]))))*np.exp(-(x-self.u[k]).dot(scipy.linalg.pinv(self.sigma[k]).dot(x.T-self.u[k].T))/2)\n",
    "            if prob > max_prob:\n",
    "                max_prob = prob\n",
    "                k_pred = k\n",
    "        return k_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting...\n",
      "converged!\n",
      "Finish fitting !\n"
     ]
    }
   ],
   "source": [
    "gmm = GMM()\n",
    "gmm.fit(training_data, 20, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmm.predict(training_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmm.predict(training_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmm.predict(training_data[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 模型评估"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
